{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5, Report\n",
    "\n",
    "https://github.com/anhaidgroup/py_entitymatching/blob/master/notebooks/vldb_demo/Demo_notebook_v6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# specify filepaths for tables A and B. \n",
    "path_A = 'tableA.csv'\n",
    "path_B = 'tableB.csv'\n",
    "# read table A; table A has 'ID' as the key attribute\n",
    "A = em.read_csv_metadata(path_A, key='id')\n",
    "# read table B; table B has 'ID' as the key attribute\n",
    "B = em.read_csv_metadata(path_B, key='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "\n",
    "# Manually set metadata properties, as current py_entitymatching.impute_table()\n",
    "# requires 'fk_ltable', 'fk_rtable', 'ltable', 'rtable' properties\n",
    "em.set_property(A, 'fk_ltable', 'id')\n",
    "em.set_property(A, 'fk_rtable', 'id')\n",
    "em.set_property(A, 'ltable', A)\n",
    "em.set_property(A, 'rtable', A)\n",
    "\n",
    "A_all_attrs = list(A.columns.values)\n",
    "A_impute_attrs = ['year','min_num_players','max_num_players','min_gameplay_time','max_gameplay_time','min_age']\n",
    "A_exclude_attrs = list(set(A_all_attrs) - set(A_impute_attrs))\n",
    "A1 = em.impute_table(A, exclude_attrs=A_exclude_attrs, missing_val='NaN', strategy='most_frequent', axis=0, val_all_nans=0, verbose=True)\n",
    "\n",
    "# Compare number of missing values to check the results\n",
    "print(sum(A['min_num_players'].isnull()))\n",
    "print(sum(A1['min_num_players'].isnull()))\n",
    "\n",
    "# Do the same thing for B\n",
    "em.set_property(B, 'fk_ltable', 'id')\n",
    "em.set_property(B, 'fk_rtable', 'id')\n",
    "em.set_property(B, 'ltable', B)\n",
    "em.set_property(B, 'rtable', B)\n",
    "\n",
    "B_all_attrs = list(B.columns.values)\n",
    "# TODO: add 'min_age'\n",
    "B_impute_attrs = ['year','min_num_players','max_num_players','min_gameplay_time','max_gameplay_time']\n",
    "B_exclude_attrs = list(set(B_all_attrs) - set(B_impute_attrs))\n",
    "B1 = em.impute_table(B, exclude_attrs=B_exclude_attrs, missing_val='NaN', strategy='most_frequent', axis=0, val_all_nans=0, verbose=True)\n",
    "\n",
    "# Compare number of missing values to check the results\n",
    "print(sum(B['min_num_players'].isnull()))\n",
    "print(sum(B1['min_num_players'].isnull()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-labeled data\n",
    "S = em.read_csv_metadata('sample_labeled.csv', \n",
    "                         key='_id',\n",
    "                         ltable=A1, rtable=B1, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n",
    "\n",
    "path_total_cand_set = 'candidate_set_C1.csv'\n",
    "total_cand_set = em.read_csv_metadata(path_total_cand_set, \n",
    "                         key='_id',\n",
    "                         ltable=A1, rtable=B1, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split S into I an J\n",
    "IJ = em.split_train_test(S, train_proportion=0.75, random_state=35)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corres = em.get_attr_corres(A1, B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features\n",
    "\n",
    "Here, we generate all the features we decided upon after our final iteration of cross validation and debugging. We only use the relevant subset of all these features in the reported iterations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a set of features\n",
    "#import pdb; pdb.set_trace();\n",
    "import py_entitymatching.feature.attributeutils as au\n",
    "import py_entitymatching.feature.simfunctions as sim\n",
    "import py_entitymatching.feature.tokenizers as tok\n",
    "\n",
    "ltable = A1\n",
    "rtable = B1\n",
    "\n",
    "# Get similarity functions for generating the features for matching\n",
    "sim_funcs = sim.get_sim_funs_for_matching()\n",
    "# Get tokenizer functions for generating the features for matching\n",
    "tok_funcs = tok.get_tokenizers_for_matching()\n",
    "\n",
    "# Get the attribute types of the input tables\n",
    "attr_types_ltable = au.get_attr_types(ltable)\n",
    "attr_types_rtable = au.get_attr_types(rtable)\n",
    "\n",
    "# Get the attribute correspondence between the input tables\n",
    "attr_corres = au.get_attr_corres(ltable, rtable)\n",
    "print(attr_types_ltable['name'])\n",
    "print(attr_types_rtable['name'])\n",
    "attr_types_ltable['name'] = 'str_bt_5w_10w'\n",
    "attr_types_rtable['name'] = 'str_bt_5w_10w'\n",
    "\n",
    "\n",
    "\n",
    "# Get the features\n",
    "F = em.get_features(ltable, rtable, attr_types_ltable,\n",
    "                                 attr_types_rtable, attr_corres,\n",
    "                                 tok_funcs, sim_funcs)\n",
    "\n",
    "#F = em.get_features_for_matching(A1, B1)\n",
    "print(F['feature_name'])\n",
    "\n",
    "# Convert the I into a set of feature vectors using F\n",
    "# Here, we add name edit distance as a feature\n",
    "include_features_2 = [\n",
    "    'min_num_players_min_num_players_lev_dist',\n",
    "    'max_num_players_max_num_players_lev_dist',\n",
    "    'min_gameplay_time_min_gameplay_time_lev_dist',\n",
    "    'max_gameplay_time_max_gameplay_time_lev_dist',\n",
    "    'name_name_lev_dist'\n",
    "]\n",
    "F_2 = F.loc[F['feature_name'].isin(include_features_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply train, test set evaluation\n",
    "I_table = em.extract_feature_vecs(I, feature_table=F_2, attrs_after='label', show_progress=False)\n",
    "J_table = em.extract_feature_vecs(J, feature_table=F_2, attrs_after='label', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_cand_set_features = em.extract_feature_vecs(total_cand_set, feature_table=F_2, show_progress=False)\n",
    "\n",
    "m = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "\n",
    "m.fit(table=I_table, exclude_attrs=['_id', 'ltable_id', 'rtable_id','label'], target_attr='label')\n",
    "\n",
    "total_cand_set_features['prediction'] = m.predict(\n",
    "    table=total_cand_set_features, \n",
    "    exclude_attrs=['_id', 'ltable_id', 'rtable_id'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join tables on matched tuples\n",
    "match_tuples = total_cand_set_features[total_cand_set_features['prediction']==1]\n",
    "match_tuples = match_tuples[['ltable_id','rtable_id']]\n",
    "A1['ltable_id'] = A1['id']\n",
    "B1['rtable_id'] = B1['id']\n",
    "joined_tables = pd.merge(match_tuples, A1, how='left', on='ltable_id')\n",
    "joined_tables = pd.merge(joined_tables, B1, how='left', on='rtable_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for n in A1.columns: \n",
    "    if not n in ['_id', 'ltable_id', 'rtable_id']:\n",
    "        joined_tables[n] =  joined_tables.apply((lambda row: row[n+'_y'] if pd.isnull(row[n+'_x']) else row[n+'_x']), axis=1)\n",
    "        joined_tables = joined_tables.drop(n+'_x', axis=1).drop(n+'_y',axis=1)\n",
    "\n",
    "joined_tables.to_csv('joined_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adventure Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from scipy.stats.stats import pearsonr\n",
    "%matplotlib inline\n",
    "\n",
    "joined_tables = pd.read_csv('new_joined_table.csv')\n",
    "joined_tables.to_csv('4_tuples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Row has incorrect number of values, (actual) 30!=29 (expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4f2991f1e648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettytable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprettytable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_joined_table.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/prettytable.pyc\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(fp, field_names, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/prettytable.pyc\u001b[0m in \u001b[0;36madd_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Row has incorrect number of values, (actual) %d!=%d (expected)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Field %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Row has incorrect number of values, (actual) 30!=29 (expected)"
     ]
    }
   ],
   "source": [
    "from StringIO import StringIO\n",
    "import prettytable    \n",
    "\n",
    "pt = prettytable.from_csv(open('new_joined_table.csv'))\n",
    "print pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 563\n",
      "Unnamed: 0 : 0\n",
      "id : 0\n",
      "ltable_id : 0\n",
      "rtable_id : 0\n",
      "id.1 : 0\n",
      "name : 0\n",
      "year : 0\n",
      "rating : 5\n",
      "rank : 169\n",
      "num_players : 0\n",
      "min_num_players : 0\n",
      "max_num_players : 0\n",
      "gameplay_time : 0\n",
      "min_gameplay_time : 0\n",
      "max_gameplay_time : 0\n",
      "min_age : 0\n",
      "complexity_weight : 39\n",
      "category : 1\n",
      "mechanisms : 49\n",
      "type : 178\n",
      "BGG_link : 0\n",
      "store_names : 0\n",
      "store_prices : 0\n",
      "links_to_buy : 0\n",
      "availability : 0\n",
      "international_store : 0\n",
      "min_price : 27\n",
      "max_price : 27\n",
      "mean_price : 27\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "joined_tables.columns\n",
    "print 'Size: ' + str(len(joined_tables))\n",
    "for c in joined_tables.columns:\n",
    "    print c + ' : '+ str(sum(joined_tables[c].isnull()))\n",
    "print (len(joined_tables.iloc[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rating vs year\n",
    "joined_tables.groupby('year').agg({'year': 'mean','rating': 'mean'}).plot.scatter(x='year', y='rating')\n",
    "\n",
    "joined_tables.plot.scatter(x='year', y='rating')\n",
    "pearsonr(\n",
    "    joined_tables['year'][joined_tables['rating'].notnull()],\n",
    "    joined_tables['rating'][joined_tables['rating'].notnull()]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complexity weight vs year\n",
    "\n",
    "joined_tables.plot.scatter(x='year', y='complexity_weight')\n",
    "pearsonr(joined_tables['year'][joined_tables['complexity_weight'].notnull()],joined_tables['complexity_weight'][joined_tables['complexity_weight'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Price mean vs year\n",
    "\n",
    "joined_tables.groupby('year').agg({'year': 'mean','mean_price': 'mean'}).plot.scatter(x='year', y='mean_price')\n",
    "joined_tables.plot.scatter(x='year', y='mean_price')\n",
    "pearsonr(joined_tables['year'][joined_tables['mean_price'].notnull()],joined_tables['mean_price'][joined_tables['mean_price'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Price mean vs rating\n",
    "\n",
    "joined_tables.plot.scatter(x='rating', y='mean_price')\n",
    "nonull = joined_tables['rating'].notnull() & joined_tables['mean_price'].notnull()\n",
    "pearsonr(joined_tables['rating'][nonull],joined_tables['mean_price'][nonull])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Num players vs complexity weight\n",
    "\n",
    "joined_tables.plot.scatter(x='complexity_weight', y='min_num_players')\n",
    "nonull = joined_tables['complexity_weight'].notnull() & joined_tables['min_num_players'].notnull()\n",
    "pearsonr(joined_tables['complexity_weight'][nonull],joined_tables['min_num_players'][nonull])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#complexity weight vs gameplay time\n",
    "\n",
    "joined_tables.plot.scatter(x='max_gameplay_time', y='complexity_weight')\n",
    "nonull = joined_tables['complexity_weight'].notnull() & joined_tables['min_gameplay_time'].notnull()\n",
    "pearsonr(joined_tables['complexity_weight'][nonull],joined_tables['min_gameplay_time'][nonull])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
